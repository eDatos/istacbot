{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de uso de stemer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"spanish\")\n",
    "spanish_stopwords = stopwords.words('spanish')\n",
    "remove_punctuation_marks = re.compile(r\"\\w+\")\n",
    "stopwords_custom = ['mes', 'dame', 'quisiera', 'gustaria', 'favor', 'por', 'numero', 'dime', 'año', 'quiero', 'saber', 'conocer', 'obtener', 'tener', 'ver', 'resultados', 'datos', 'informacion', 'listado']\n",
    "for stopword in stopwords_custom: spanish_stopwords.append(stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_stopwords.remove('para')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de',\n",
       " 'la',\n",
       " 'que',\n",
       " 'el',\n",
       " 'en',\n",
       " 'y',\n",
       " 'a',\n",
       " 'los',\n",
       " 'del',\n",
       " 'se',\n",
       " 'las',\n",
       " 'por',\n",
       " 'un',\n",
       " 'con',\n",
       " 'no',\n",
       " 'una',\n",
       " 'su',\n",
       " 'al',\n",
       " 'lo',\n",
       " 'como',\n",
       " 'más',\n",
       " 'pero',\n",
       " 'sus',\n",
       " 'le',\n",
       " 'ya',\n",
       " 'o',\n",
       " 'este',\n",
       " 'sí',\n",
       " 'porque',\n",
       " 'esta',\n",
       " 'entre',\n",
       " 'cuando',\n",
       " 'muy',\n",
       " 'sin',\n",
       " 'sobre',\n",
       " 'también',\n",
       " 'me',\n",
       " 'hasta',\n",
       " 'hay',\n",
       " 'donde',\n",
       " 'quien',\n",
       " 'desde',\n",
       " 'todo',\n",
       " 'nos',\n",
       " 'durante',\n",
       " 'todos',\n",
       " 'uno',\n",
       " 'les',\n",
       " 'ni',\n",
       " 'contra',\n",
       " 'otros',\n",
       " 'ese',\n",
       " 'eso',\n",
       " 'ante',\n",
       " 'ellos',\n",
       " 'e',\n",
       " 'esto',\n",
       " 'mí',\n",
       " 'antes',\n",
       " 'algunos',\n",
       " 'qué',\n",
       " 'unos',\n",
       " 'yo',\n",
       " 'otro',\n",
       " 'otras',\n",
       " 'otra',\n",
       " 'él',\n",
       " 'tanto',\n",
       " 'esa',\n",
       " 'estos',\n",
       " 'mucho',\n",
       " 'quienes',\n",
       " 'nada',\n",
       " 'muchos',\n",
       " 'cual',\n",
       " 'poco',\n",
       " 'ella',\n",
       " 'estar',\n",
       " 'estas',\n",
       " 'algunas',\n",
       " 'algo',\n",
       " 'nosotros',\n",
       " 'mi',\n",
       " 'mis',\n",
       " 'tú',\n",
       " 'te',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'tus',\n",
       " 'ellas',\n",
       " 'nosotras',\n",
       " 'vosostros',\n",
       " 'vosostras',\n",
       " 'os',\n",
       " 'mío',\n",
       " 'mía',\n",
       " 'míos',\n",
       " 'mías',\n",
       " 'tuyo',\n",
       " 'tuya',\n",
       " 'tuyos',\n",
       " 'tuyas',\n",
       " 'suyo',\n",
       " 'suya',\n",
       " 'suyos',\n",
       " 'suyas',\n",
       " 'nuestro',\n",
       " 'nuestra',\n",
       " 'nuestros',\n",
       " 'nuestras',\n",
       " 'vuestro',\n",
       " 'vuestra',\n",
       " 'vuestros',\n",
       " 'vuestras',\n",
       " 'esos',\n",
       " 'esas',\n",
       " 'estoy',\n",
       " 'estás',\n",
       " 'está',\n",
       " 'estamos',\n",
       " 'estáis',\n",
       " 'están',\n",
       " 'esté',\n",
       " 'estés',\n",
       " 'estemos',\n",
       " 'estéis',\n",
       " 'estén',\n",
       " 'estaré',\n",
       " 'estarás',\n",
       " 'estará',\n",
       " 'estaremos',\n",
       " 'estaréis',\n",
       " 'estarán',\n",
       " 'estaría',\n",
       " 'estarías',\n",
       " 'estaríamos',\n",
       " 'estaríais',\n",
       " 'estarían',\n",
       " 'estaba',\n",
       " 'estabas',\n",
       " 'estábamos',\n",
       " 'estabais',\n",
       " 'estaban',\n",
       " 'estuve',\n",
       " 'estuviste',\n",
       " 'estuvo',\n",
       " 'estuvimos',\n",
       " 'estuvisteis',\n",
       " 'estuvieron',\n",
       " 'estuviera',\n",
       " 'estuvieras',\n",
       " 'estuviéramos',\n",
       " 'estuvierais',\n",
       " 'estuvieran',\n",
       " 'estuviese',\n",
       " 'estuvieses',\n",
       " 'estuviésemos',\n",
       " 'estuvieseis',\n",
       " 'estuviesen',\n",
       " 'estando',\n",
       " 'estado',\n",
       " 'estada',\n",
       " 'estados',\n",
       " 'estadas',\n",
       " 'estad',\n",
       " 'he',\n",
       " 'has',\n",
       " 'ha',\n",
       " 'hemos',\n",
       " 'habéis',\n",
       " 'han',\n",
       " 'haya',\n",
       " 'hayas',\n",
       " 'hayamos',\n",
       " 'hayáis',\n",
       " 'hayan',\n",
       " 'habré',\n",
       " 'habrás',\n",
       " 'habrá',\n",
       " 'habremos',\n",
       " 'habréis',\n",
       " 'habrán',\n",
       " 'habría',\n",
       " 'habrías',\n",
       " 'habríamos',\n",
       " 'habríais',\n",
       " 'habrían',\n",
       " 'había',\n",
       " 'habías',\n",
       " 'habíamos',\n",
       " 'habíais',\n",
       " 'habían',\n",
       " 'hube',\n",
       " 'hubiste',\n",
       " 'hubo',\n",
       " 'hubimos',\n",
       " 'hubisteis',\n",
       " 'hubieron',\n",
       " 'hubiera',\n",
       " 'hubieras',\n",
       " 'hubiéramos',\n",
       " 'hubierais',\n",
       " 'hubieran',\n",
       " 'hubiese',\n",
       " 'hubieses',\n",
       " 'hubiésemos',\n",
       " 'hubieseis',\n",
       " 'hubiesen',\n",
       " 'habiendo',\n",
       " 'habido',\n",
       " 'habida',\n",
       " 'habidos',\n",
       " 'habidas',\n",
       " 'soy',\n",
       " 'eres',\n",
       " 'es',\n",
       " 'somos',\n",
       " 'sois',\n",
       " 'son',\n",
       " 'sea',\n",
       " 'seas',\n",
       " 'seamos',\n",
       " 'seáis',\n",
       " 'sean',\n",
       " 'seré',\n",
       " 'serás',\n",
       " 'será',\n",
       " 'seremos',\n",
       " 'seréis',\n",
       " 'serán',\n",
       " 'sería',\n",
       " 'serías',\n",
       " 'seríamos',\n",
       " 'seríais',\n",
       " 'serían',\n",
       " 'era',\n",
       " 'eras',\n",
       " 'éramos',\n",
       " 'erais',\n",
       " 'eran',\n",
       " 'fui',\n",
       " 'fuiste',\n",
       " 'fue',\n",
       " 'fuimos',\n",
       " 'fuisteis',\n",
       " 'fueron',\n",
       " 'fuera',\n",
       " 'fueras',\n",
       " 'fuéramos',\n",
       " 'fuerais',\n",
       " 'fueran',\n",
       " 'fuese',\n",
       " 'fueses',\n",
       " 'fuésemos',\n",
       " 'fueseis',\n",
       " 'fuesen',\n",
       " 'sintiendo',\n",
       " 'sentido',\n",
       " 'sentida',\n",
       " 'sentidos',\n",
       " 'sentidas',\n",
       " 'siente',\n",
       " 'sentid',\n",
       " 'tengo',\n",
       " 'tienes',\n",
       " 'tiene',\n",
       " 'tenemos',\n",
       " 'tenéis',\n",
       " 'tienen',\n",
       " 'tenga',\n",
       " 'tengas',\n",
       " 'tengamos',\n",
       " 'tengáis',\n",
       " 'tengan',\n",
       " 'tendré',\n",
       " 'tendrás',\n",
       " 'tendrá',\n",
       " 'tendremos',\n",
       " 'tendréis',\n",
       " 'tendrán',\n",
       " 'tendría',\n",
       " 'tendrías',\n",
       " 'tendríamos',\n",
       " 'tendríais',\n",
       " 'tendrían',\n",
       " 'tenía',\n",
       " 'tenías',\n",
       " 'teníamos',\n",
       " 'teníais',\n",
       " 'tenían',\n",
       " 'tuve',\n",
       " 'tuviste',\n",
       " 'tuvo',\n",
       " 'tuvimos',\n",
       " 'tuvisteis',\n",
       " 'tuvieron',\n",
       " 'tuviera',\n",
       " 'tuvieras',\n",
       " 'tuviéramos',\n",
       " 'tuvierais',\n",
       " 'tuvieran',\n",
       " 'tuviese',\n",
       " 'tuvieses',\n",
       " 'tuviésemos',\n",
       " 'tuvieseis',\n",
       " 'tuviesen',\n",
       " 'teniendo',\n",
       " 'tenido',\n",
       " 'tenida',\n",
       " 'tenidos',\n",
       " 'tenidas',\n",
       " 'tened',\n",
       " 'mes',\n",
       " 'dame',\n",
       " 'quisiera',\n",
       " 'gustaria',\n",
       " 'favor',\n",
       " 'por',\n",
       " 'numero',\n",
       " 'dime',\n",
       " 'año',\n",
       " 'quiero',\n",
       " 'saber',\n",
       " 'conocer',\n",
       " 'obtener',\n",
       " 'tener',\n",
       " 'ver',\n",
       " 'resultados',\n",
       " 'datos',\n",
       " 'informacion',\n",
       " 'listado']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanish_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de uso corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file  = open(\"istac_chatbot/data/localidades.txt\", mode=\"r\", encoding=\"utf-8\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens_stemmed = [stemmer.stem(token)for token in tokens ]\n",
    "    spanish_stopwords_stemmed = [stemmer.stem(stopword)for stopword in spanish_stopwords]\n",
    "    filtered_words = [word for word in tokens_stemmed if word not in spanish_stopwords_stemmed and re.match(remove_punctuation_marks, word) != None]\n",
    "    frase = ''\n",
    "    for word in filtered_words:\n",
    "        frase = frase + word + ' '\n",
    "    return frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canari \n",
      "arrecif \n",
      "har \n",
      "san bartolom \n",
      "teguis \n",
      "tias \n",
      "tinaj \n",
      "yaiz \n",
      "antigu \n",
      "betancuri \n",
      "oliv \n",
      "paj \n",
      "puert rosari \n",
      "tuinej \n",
      "agaet \n",
      "agüim \n",
      "arten \n",
      "aruc \n",
      "firg \n",
      "gald \n",
      "ingeni \n",
      "mogan \n",
      "moy \n",
      "palm gran canari \n",
      "san bartolom tirajan \n",
      "alde san nicolas \n",
      "sant brig \n",
      "sant luc tirajan \n",
      "sant mar gui gran canari \n",
      "tejed \n",
      "teld \n",
      "teror \n",
      "valsequill gran canari \n",
      "vallesec \n",
      "veg san mate \n",
      "adej \n",
      "araf \n",
      "aric \n",
      "aron \n",
      "buenav nort \n",
      "candelari \n",
      "fasni \n",
      "garach \n",
      "granadill abon \n",
      "guanch \n",
      "gui isor \n",
      "güim \n",
      "icod vin \n",
      "san cristobal la lagun \n",
      "matanz acentej \n",
      "orotav \n",
      "puert la cruz \n",
      "realej \n",
      "rosari \n",
      "san juan rambl \n",
      "san miguel abon \n",
      "sant cruz tenerif \n",
      "sant ursul \n",
      "santiag teid \n",
      "sauzal \n",
      "sil \n",
      "tacoront \n",
      "tanqu \n",
      "teguest \n",
      "victori acentej \n",
      "vilaflor chasn \n",
      "agul \n",
      "alajer \n",
      "hermigu \n",
      "san sebastian la gomer \n",
      "vall gran rey \n",
      "valleherm \n",
      "barlovent \n",
      "breñ alta \n",
      "breñ baj \n",
      "fuencalient la palm \n",
      "garaf \n",
      "llan aridan \n",
      "pas \n",
      "puntagord \n",
      "puntallan \n",
      "san andres sauc \n",
      "sant cruz la palm \n",
      "tazacort \n",
      "tijaraf \n",
      "vill maz \n",
      "fronter \n",
      "valverd \n",
      "pin el hierr \n",
      "lanzarot \n",
      "fuerteventur \n",
      "gran canari \n",
      "tenerif \n",
      "la gomer \n",
      "la palm \n",
      "el hierr \n",
      "ceut melill \n",
      "andaluc \n",
      "aragon \n",
      "princip asturi \n",
      "illes balears \n",
      "cantabri \n",
      "castill leon \n",
      "castill la manch \n",
      "cataluñ \n",
      "comunitat valencian \n",
      "extremadur \n",
      "galici \n",
      "comun madr \n",
      "madr \n",
      "region murci \n",
      "comun foral navarr \n",
      "navarr \n",
      "pais vasc \n",
      "rioj \n",
      "ceut \n",
      "melill \n",
      "albacet \n",
      "alacant \n",
      "alic \n",
      "almer \n",
      "arab \n",
      "alav \n",
      "asturi \n",
      "avil \n",
      "badajoz \n",
      "illes balears \n",
      "balears \n",
      "islas balear \n",
      "balear \n",
      "barcelon \n",
      "bizkai \n",
      "burg \n",
      "cacer \n",
      "cadiz \n",
      "cantabri \n",
      "castell \n",
      "castellon \n",
      "ceut \n",
      "ciud real \n",
      "cordob \n",
      "coruñ \n",
      "a coruñ \n",
      "cuenc \n",
      "gipuzko \n",
      "giron \n",
      "geron \n",
      "gran \n",
      "guadalaj \n",
      "huelv \n",
      "huesc \n",
      "jaen \n",
      "leon \n",
      "lle \n",
      "ler \n",
      "lug \n",
      "madr \n",
      "malag \n",
      "melill \n",
      "murci \n",
      "navarr \n",
      "ourens \n",
      "palenci \n",
      "palm \n",
      "pontevedr \n",
      "rioj \n",
      "salamanc \n",
      "sant cruz tenerif \n",
      "segovi \n",
      "sevill \n",
      "sori \n",
      "tarragon \n",
      "teruel \n",
      "toled \n",
      "valladol \n",
      "zamor \n",
      "zaragoz \n",
      "valènci \n",
      "valenci \n",
      "lanzarot \n",
      "lanzarot este \n",
      "lanzarot nort \n",
      "lanzarot suroest \n",
      "fuerteventur \n",
      "fuerteventur centr \n",
      "fuerteventur nort \n",
      "fuerteventur sur \n",
      "gran canari are metropolitan \n",
      "gran canari are metropolitan \n",
      "gran canari nort \n",
      "gran canari nort centr nort \n",
      "gran canari nort noroest \n",
      "gran canari nort oest \n",
      "gran canari sur \n",
      "gran canari sur sur \n",
      "gran canari sur surest \n",
      "tenerif are metropolitan \n",
      "tenerif are metropolitan \n",
      "tenerif nort \n",
      "tenerif nort acentej \n",
      "tenerif nort daut \n",
      "tenerif nort icod \n",
      "tenerif nort vall la orotav \n",
      "tenerif sur \n",
      "tenerif sur abon \n",
      "tenerif sur suroest \n",
      "tenerif sur vall güim \n",
      "la gomer \n",
      "la gomer nort \n",
      "la gomer sur \n",
      "la palm \n",
      "la palm capitalin \n",
      "la palm norest \n",
      "la palm noroest \n",
      "la palm vall aridan \n",
      "el hierr \n",
      "el hierr el hierr \n",
      "españ \n"
     ]
    }
   ],
   "source": [
    "list_loc = []\n",
    "for line in lines:\n",
    "    if (re.match(r\"%.+\", line) or (re.match(r\"@.+\", line)) or (re.match(r\"~.+\", line))):\n",
    "        print (line)\n",
    "    else:\n",
    "        list_loc.append(stemming(line))\n",
    "        print(stemming(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_words = [stemmer.stem(word) for word in tokens if word not in stopwords.words('spanish') and re.match(remove_punctuation_marks, word) != None]\n",
    "    frase = ''\n",
    "    for word in filtered_words: \n",
    "        frase = frase + word + ' '\n",
    "    return frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sant cruz tenerif \n",
      "fuerteventur \n",
      "la palm \n",
      "illes balears \n",
      "navarr \n",
      "rioj \n",
      "melill \n",
      "ceut \n",
      "madr \n",
      "gran canari are metropolitan \n",
      "tenerif are metropolitan \n"
     ]
    }
   ],
   "source": [
    "for loc in list_loc:\n",
    "    list_loc.remove(loc)\n",
    "    if (loc in list_loc):\n",
    "        print(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_stopwords = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase = \"holaa!!! me gustaria conocer los datos de los afiliados a la seguridad social en Tenerife - sur durante en el año 2015\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_punctuation_marks = re.compile(r\"\\w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ácañ'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(remove_punctuation_marks, \"ácañ!!!\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words = [stemmer.stem(word) for word in tokens if word not in stopwords.words('spanish') and re.match(remove_punctuation_marks, word) != None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hola',\n",
       " 'gustari',\n",
       " 'conoc',\n",
       " 'dat',\n",
       " 'afili',\n",
       " 'segur',\n",
       " 'social',\n",
       " 'tenerif',\n",
       " 'sur',\n",
       " 'año',\n",
       " '2015']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase = ''\n",
    "for word in filtered_words: frase = frase + word + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hola gustari conoc dat afili segur social tenerif sur año 2015 '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
